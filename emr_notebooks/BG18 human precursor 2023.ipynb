{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T23:08:08.178996Z",
     "iopub.status.busy": "2023-06-20T23:08:08.178684Z",
     "iopub.status.idle": "2023-06-20T23:09:15.768849Z",
     "shell.execute_reply": "2023-06-20T23:09:15.768121Z",
     "shell.execute_reply.started": "2023-06-20T23:08:08.178971Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "import tempfile\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import subprocess\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\"\"\"\n",
    "Import Parquet As a DataFrame\n",
    "\"\"\"\n",
    "\n",
    "##Read in parquet file from public S3 bucket\n",
    "parquet_s3 = \"s3://steichenetalpublicdata/analyzed_sequences/parquet\"\n",
    "df_spark = spark.read.parquet(parquet_s3)\n",
    "\n",
    "##Verify count \n",
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a query class\n",
    "The query class can hold our spark query until it's time to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T23:09:45.743489Z",
     "iopub.status.busy": "2023-06-20T23:09:45.743160Z",
     "iopub.status.idle": "2023-06-20T23:12:43.771692Z",
     "shell.execute_reply": "2023-06-20T23:12:43.770801Z",
     "shell.execute_reply.started": "2023-06-20T23:09:45.743455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Query():\n",
    "    \n",
    "    '''An example query class to hold query parameters'''\n",
    "    \n",
    "    def __init__(self,q_name,length='',v_fam=\"\",v_gene=\"\",d_gene=\"\",j_gene=\"\",regex=\"\",ez_donor=\"\"):\n",
    "        self.query_name = q_name\n",
    "        self.v_fam = v_fam\n",
    "        self.v_gene = v_gene\n",
    "        self.j_gene = j_gene\n",
    "        self.d_gene = d_gene\n",
    "        self.ez_donor = ez_donor\n",
    "        \n",
    "        if not length:\n",
    "            raise Exception(\"Length must be supplied\")\n",
    "        self.length = length\n",
    "        self.regular_expression = regex\n",
    "    \n",
    "    \n",
    "    \n",
    "    def apply(self,df):\n",
    "        \n",
    "        '''Apply function will take in spark dataframe and apply query parameters to it if they exist\n",
    "        \n",
    "           Returns a filtered dataframe\n",
    "        '''\n",
    "        self.queried_dataframe = \"\"\n",
    "        \n",
    "        ##Lets get length\n",
    "        \n",
    "        self.queried_dataframe = df.filter(F.length(df.cdr3_aa) > self.length)\n",
    "        \n",
    "        ##If the rest of these were specified, add them to the filter\n",
    "        if self.v_fam:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.v_fam == self.v_fam)\n",
    "        \n",
    "        if self.v_gene:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.v_gene == self.v_gene)\n",
    "     \n",
    "        if self.d_gene:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.d_gene == self.d_gene)       \n",
    "        \n",
    "        if self.j_gene:\n",
    "            self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.j_gene == self.j_gene)       \n",
    "        \n",
    "\n",
    "        if self.regular_expression:\n",
    "             self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.cdr3_aa.rlike(self.regular_expression))\n",
    "        \n",
    "        if self.ez_donor:\n",
    "             self.queried_dataframe = self.queried_dataframe.filter(self.queried_dataframe.ez_donor == self.ez_donor)\n",
    "            \n",
    "        print(\"Found {} sequences\".format(self.queried_dataframe.count()))\n",
    "        return self.queried_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 1: ≥22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_1 = Query('BG18_search.1',length=21)\n",
    "queried1_df = my_query_1.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas1_df = queried1_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas1_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 2: ≥22, D3-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_2 = Query('BG18_search.2',d_gene='IGHD3-3',length=21)\n",
    "queried2_df = my_query_2.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas2_df = queried2_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas2_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 3: ≥22, D3-3, FGV anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_3 = Query('BG18_search.3',d_gene='IGHD3-3',length=21, regex=r'FGV')\n",
    "queried3_df = my_query_3.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas3_df = queried3_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas3_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 4: ≥22, D3-3, FGV starting at position 7, 8, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_4_7 = Query('BG18_search.4.7',d_gene='IGHD3-3',length=21, regex=r'^......FGV')\n",
    "my_query_4_8 = Query('BG18_search.4.8',d_gene='IGHD3-3',length=21, regex=r'^.......FGV')\n",
    "my_query_4_9 = Query('BG18_search.4.9',d_gene='IGHD3-3',length=21, regex=r'^........FGV')\n",
    "queried4_7_df = my_query_4_7.apply(df_spark)\n",
    "queried4_8_df = my_query_4_8.apply(df_spark)\n",
    "queried4_9_df = my_query_4_9.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas47_df = queried4_7_df.select('_id','ez_donor').toPandas()\n",
    "pandas48_df = queried4_8_df.select('_id','ez_donor').toPandas()\n",
    "pandas49_df = queried4_9_df.select('_id','ez_donor').toPandas()\n",
    "\n",
    "pandas4_df = pandas.concat([pandas47_df,pandas48_df,pandas49_df])\n",
    "\n",
    "counts = pandas4_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 5: ≥22, D3-3, FGV starting at position 7, 8, 9, E at position 7 past FGV (example:.......FGV....E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_5_7 = Query('BG18_search.5.7',d_gene='IGHD3-3',length=21, regex=r'^......FGV....E')\n",
    "my_query_5_8 = Query('BG18_search.5.8',d_gene='IGHD3-3',length=21, regex=r'^.......FGV....E')\n",
    "my_query_5_9 = Query('BG18_search.5.9',d_gene='IGHD3-3',length=21, regex=r'^........FGV....E')\n",
    "queried5_7_df = my_query_5_7.apply(df_spark)\n",
    "queried5_8_df = my_query_5_8.apply(df_spark)\n",
    "queried5_9_df = my_query_5_9.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas57_df = queried5_7_df.select('_id','ez_donor').toPandas()\n",
    "pandas58_df = queried5_8_df.select('_id','ez_donor').toPandas()\n",
    "pandas59_df = queried5_9_df.select('_id','ez_donor').toPandas()\n",
    "\n",
    "pandas5_df = pandas.concat([pandas57_df,pandas58_df,pandas59_df])\n",
    "\n",
    "counts = pandas5_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 6: ≥22, D3-3, FGV anywhere, E at position 7 past FGV (example:.......FGV....E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_6 = Query('BG18_search.6',d_gene='IGHD3-3',length=21, regex=r'FGV....E')\n",
    "queried6_df = my_query_6.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas6_df = queried6_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas6_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency 7: D3-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make query class and pass the input object from above to apply\n",
    "my_query_7 = Query('BG18_search.7',d_gene='IGHD3-3',length=1)\n",
    "queried7_df = my_query_7.apply(df_spark)\n",
    "\n",
    "# Turn it into a pandas dataframe for frequency calculation\n",
    "pandas7_df = queried7_df.select('_id','ez_donor').toPandas()\n",
    "counts = pandas7_df.groupby('ez_donor').count().rename({'_id':'count'},axis=1).sort_values('count')\n",
    "df_count = df_spark.groupby('ez_donor').count().toPandas()\n",
    "merged = counts.reset_index().merge(df_count, on='ez_donor')\n",
    "merged['normal'] = merged['count_x']/merged['count_y']*1000000\n",
    "merged.sort_values('ez_donor')[['ez_donor','normal']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
